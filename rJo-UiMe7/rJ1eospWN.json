{"_id":"rJ1eospWN","title":"categorical_crossentropy vs sparse_categorical_crossentropy or multi label loss function in keras ","body":{"entityMap":{},"blocks":[{"key":"ag6qs","text":"categorical_crossentropy vs sparse_categorical_crossentropy or multi label loss function in keras ","type":"header-one","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"3qh2d","text":"model.compile(loss = 'categorical_crossentropy',","type":"custom-code-block-python","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"ehlg1","text":"              optimizer = 'adam',","type":"custom-code-block-python","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"4hurv","text":"              metrics = ['accuracy'])","type":"custom-code-block-python","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"boknl","text":"\nIf your targets are one-hot encoded, use categorical_crossentropy.\n        Examples of one-hot encodings:\n            [1,0,0]\n            [0,1,0]\n            [0,0,1]\nBut if your targets are integers, use sparse_categorical_crossentropy.\n        Examples of integer encodings (for the sake of completion):\n            1\n            2\n            3\n","type":"header-two","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"65j2s","text":"","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"ema2n","text":"","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"7m0i3","text":"","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}},{"key":"59kd9","text":"","type":"unstyled","depth":0,"inlineStyleRanges":[],"entityRanges":[],"data":{}}]},"dateCreated":"2019-01-05T03:56:23.107Z","lastUpdated":"2019-01-05T04:00:04.776Z"}
